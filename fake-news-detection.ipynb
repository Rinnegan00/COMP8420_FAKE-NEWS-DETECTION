{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0593959-1f0f-4844-84da-c1ae6cbc5b91",
   "metadata": {},
   "source": [
    "# Step 1: Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78f53e0-29d7-408c-9233-d86227668adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load & clean the dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4910688b-50d1-41ab-8568-a14e3552e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TSV\n",
    "df = pd.read_csv(\"train.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735e7e24-b576-4c5a-82f9-c0b3fc128f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       10240 non-null  object \n",
      " 1   1       10240 non-null  object \n",
      " 2   2       10240 non-null  object \n",
      " 3   3       10238 non-null  object \n",
      " 4   4       10238 non-null  object \n",
      " 5   5       7342 non-null   object \n",
      " 6   6       8030 non-null   object \n",
      " 7   7       10238 non-null  object \n",
      " 8   8       10238 non-null  float64\n",
      " 9   9       10238 non-null  float64\n",
      " 10  10      10238 non-null  float64\n",
      " 11  11      10238 non-null  float64\n",
      " 12  12      10238 non-null  float64\n",
      " 13  13      10138 non-null  object \n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e47bac-ac01-46c7-9b39-e983bd6b1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column assignment (based on Liar dataset)\n",
    "df.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job', \n",
    "              'state', 'party', 'barely_true_counts', 'false_counts', 'half_true_counts', \n",
    "              'mostly_true_counts', 'pants_on_fire_counts', 'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395ab761-69ff-4865-8d99-f6f150a5e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only statement and label\n",
    "df = df[['statement', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5bf1413-320b-48aa-aa23-ef2ac2d8a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid labels\n",
    "valid_labels = ['true', 'false']\n",
    "df = df[df['label'].isin(valid_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5f0556-db7c-4fec-ad44-3b511a825b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels to binary\n",
    "df['label'] = df['label'].map({'true': 1, 'false': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c185197f-a202-44cc-953c-eb0d55a7177d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When Mitt Romney was governor of Massachusetts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>McCain opposed a requirement that the governme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            statement  label\n",
       "0   Says the Annies List political group supports ...      0\n",
       "3   Health care reform legislation is likely to ma...      0\n",
       "5   The Chicago Bears have had more starting quart...      1\n",
       "12  When Mitt Romney was governor of Massachusetts...      0\n",
       "16  McCain opposed a requirement that the governme...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa204d8-7fe2-4dbb-92ac-1c1c3068ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3671 entries, 0 to 10238\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   statement  3671 non-null   object\n",
      " 1   label      3671 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 86.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc23abc-7501-46a6-98af-5ceef9e561ea",
   "metadata": {},
   "source": [
    "# Step 2: Tokenization with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb1cd1e-03e2-4a7a-827f-2d0e82eccd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40715b91-20f2-4aec-b166-16640d607deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenization and Dataset Preparation\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d690c678-95f7-4b46-9376-cc997bf1f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11d2641a-5165-4afc-aebe-95d9cb2be912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the statements\n",
    "tokens = tokenizer(\n",
    "    list(df['statement']),\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24a0b476-3983-4fe0-94ff-47554b8816d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "labels = torch.tensor(df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "354705f3-238d-4b0e-b08f-96f635ee409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80/20)\n",
    "input_ids_train, input_ids_test, \\\n",
    "attention_mask_train, attention_mask_test, \\\n",
    "labels_train, labels_test = train_test_split(\n",
    "    tokens['input_ids'], tokens['attention_mask'], labels,\n",
    "    test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70f733-82a2-4d9a-aeb8-021646636b04",
   "metadata": {},
   "source": [
    "# Step 3: Load BERT and Prepare for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd1d52ea-4c01-47eb-9a4a-80f2cf4ba081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0136ac0f-045d-4228-a1e7-2d69173656f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT with classification head (2 classes)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9a83501-d4c0-4bbd-8864-2ef4011d125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3be2a970-b70d-4ecf-8ed4-05eb25d6d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_loader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7309c5-4804-4a3c-8562-aebf26385f19",
   "metadata": {},
   "source": [
    "# Step 4: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dab3c12-62fd-460b-94fa-e6e96d4906a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4d1decc-147b-4bc8-aac8-99aa29554af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8d9894f-74ba-4004-a7f8-281bf8d996f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = len(train_loader) * epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59ddf31c-88b3-49d9-b4f2-3d670bc215a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 184/184 [09:06<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.6729\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 184/184 [09:15<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5997\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 184/184 [09:39<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.4538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average training loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df30ff-a376-4cd3-8bd7-2503360352f5",
   "metadata": {},
   "source": [
    "# Step 5: Model Evaluation (Accuracy, F1 Score, Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5ea11f02-c173-41c0-81ab-141c50ad3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c87ebaa-46b0-454b-bda1-af231e54e5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "62584801-7ea4-45c5-b09a-b02573803697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c05ad75a-1ea7-4292-8f08-a098b03adfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f49af939-b111-49e6-bb96-caa742f6f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1a92741e-28b2-4505-a458-138f7546257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and F1\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "61ab7c8a-da66-412a-809e-4f12d5d44b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6272\n",
      "F1 Score: 0.6277\n",
      "\n",
      "Confusion Matrix:\n",
      "[[230 161]\n",
      " [113 231]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f140498f-70cb-449c-a719-957c015ff8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.59      0.63       391\n",
      "        True       0.59      0.67      0.63       344\n",
      "\n",
      "    accuracy                           0.63       735\n",
      "   macro avg       0.63      0.63      0.63       735\n",
      "weighted avg       0.63      0.63      0.63       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"False\", \"True\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94eebf-6b20-4216-a875-2f3386a144d3",
   "metadata": {},
   "source": [
    "# Step 6: Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "805dd6cc-e0d8-42e5-bb7b-ee6a2b9db13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_bert_model1\\\\tokenizer_config.json',\n",
       " 'saved_bert_model1\\\\special_tokens_map.json',\n",
       " 'saved_bert_model1\\\\vocab.txt',\n",
       " 'saved_bert_model1\\\\added_tokens.json')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer to a local folder\n",
    "model_save_path = \"saved_bert_model1\"\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a1a262-6c05-47a8-bb6c-f2578a88da1c",
   "metadata": {},
   "source": [
    "# Step 7: Deploying with FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1b7c88e8-4f18-4391-bbe3-c9e7e40c4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn transformers torch nest_asyncio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9d1bd-3fa4-4247-ab30-445c662680fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [4384]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Allow running FastAPI in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_path = \"saved_bert_model1\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Setup FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "class TextInput(BaseModel):\n",
    "    text: str\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(input: TextInput):\n",
    "    inputs = tokenizer(\n",
    "        input.text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    label = \"true\" if prediction == 1 else \"false\"\n",
    "    return {\"prediction\": label}\n",
    "\n",
    "# Run server inside notebook\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183ac90-2587-44a1-8e5d-436e7c16bb36",
   "metadata": {},
   "source": [
    "# Step 8: Integrate ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee098eed-6f82-4687-a700-233891623f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1ea3ca5-5b39-475b-b5bd-7b1a345a76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def classify_with_chatgpt(statement):\n",
    "    prompt = f\"\"\"You are a fact-checking assistant. Classify the following claim as either \"true\" or \"false\":\n",
    "\n",
    "Claim: \"{statement}\"\n",
    "\n",
    "Your response should be just one word: \"true\" or \"false\".\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Or \"gpt-4\" if you want\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1,\n",
    "            temperature=0\n",
    "        )\n",
    "        label = response['choices'][0]['message']['content'].strip().lower()\n",
    "        return label if label in ['true', 'false'] else 'unknown'\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return \"error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7add9ce4-83c7-4937-9999-0f20449ec680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Incorrect API key provided: sk-or-v1*************************************************************611b. You can find your API key at https://platform.openai.com/account/api-keys.\n",
      "Claim: Everything I have said (on the campaign trail) has been factually accurate.\n",
      "True Label: false | ChatGPT: error\n",
      "\n",
      "Error: Incorrect API key provided: sk-or-v1*************************************************************611b. You can find your API key at https://platform.openai.com/account/api-keys.\n",
      "Claim: Mickey Mouse was registered to vote (in Florida).\n",
      "True Label: false | ChatGPT: error\n",
      "\n",
      "Error: Incorrect API key provided: sk-or-v1*************************************************************611b. You can find your API key at https://platform.openai.com/account/api-keys.\n",
      "Claim: John McCain accused Barack Obama \"of letting infants die.\"\n",
      "True Label: false | ChatGPT: error\n",
      "\n",
      "Error: Incorrect API key provided: sk-or-v1*************************************************************611b. You can find your API key at https://platform.openai.com/account/api-keys.\n",
      "Claim: Says President Barack Obama said when we got bin Laden, terrorism problem solved.\n",
      "True Label: false | ChatGPT: error\n",
      "\n",
      "Error: Incorrect API key provided: sk-or-v1*************************************************************611b. You can find your API key at https://platform.openai.com/account/api-keys.\n",
      "Claim: On the Keystone XL pipeline\n",
      "True Label: true | ChatGPT: error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample 5 rows from the dataframe\n",
    "sample_df = df.sample(5)\n",
    "\n",
    "# Loop through and classify each claim\n",
    "for i, row in sample_df.iterrows():\n",
    "    claim = row['statement']\n",
    "    true_label = 'true' if row['label'] == 1 else 'false'\n",
    "\n",
    "    prediction = classify_with_chatgpt(claim)\n",
    "    print(f\"Claim: {claim}\\nTrue Label: {true_label} | ChatGPT: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca6cca3-2f70-4982-8b9c-192c34495207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
